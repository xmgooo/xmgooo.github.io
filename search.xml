<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Fastdfs分布式文件存储]]></title>
    <url>%2F2018%2F11%2F10%2FFastdfs%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[Fastdfs分布式文件存储 简介&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fastdfs是一款比较轻量级的开源分布式文件系统，作者是余庆大大在0几年业余时间用c撸出来的(工作不饱和，加班不够啊:) ，现任淘宝网开放平台技术部资深架构师,Fastdfs在小文件存储方面性能优异，在淘宝和京东都有实例的应用案例，去哪儿目前使用的是seaweedfs，基于Facebook的图片存储论文用go语言开发的一套存储系统，使用起来也是非常方便，相比Fastdfs更加现代化，这个日后研究，直接进入正题。 相关术语• Tracker Server：跟踪服务器，主要负责任务调度,请求分发负载的工作。记录storage server的状态，是连接Client和Storage server的枢纽。• Storage Server：存储服务器，文件和meta data都保存到存储服务器上。• group：组，也可称为卷。同组内服务器上的文件是完全相同的。• 文件标识：包括两部分：组名和文件名（包含路径）。• meta data：文件相关属性，键值对（Key Value Pair）方式，如：width=1024,heigth=768 系统架构 从图中可以看出两大核心部分，trakcer跟踪器，storage存储节点，跟踪器主要负责路由分发，任务调度，与clent端直接交互，storage则负责存储实际的数据，两部分都支持主流的分布式主从配置，即master/slave模式，在请求量大时可加大trakcer集群规模，在存储大文件或读写频繁时可加大storage集群规模，非常容易的就能做到局部和全局的横向扩展，如果对这两部分理解还很模糊我们看下文件上传下载的流程图 • 1. client询问tracker上传到的storage，不需要附加参数；• 2.tracker返回一台可用的storage；• 3.client直接和storage通讯完成文件上传。 • 1. client询问tracker下载文件的storage，参数为文件标识（组名和文件名）；• 2.tracker返回一台可用的storage；• 3.client直接和storage通讯完成文件下载。 同步机制•同一组内的storage server之间是对等的，文件上传、删除等操作可以在任意一台storage server上进行；•文件同步只在同组内的storage server之间进行，采用push方式，即源服务器同步给目标服务器；•源头数据才需要同步，备份数据不需要再次同步，否则就构成环路了；•上述第二条规则有个例外，就是新增加一台storage server时，由已有的一台storage server将已有的所有数据（包括源头数据和备份数据）同步给该新增服务器，当某台master storage宕机时，依据选举算法此master节点下的某台slave storage会自动切换为master，并将原master剔除集群，原master重启后，会自动以slave的角色重新加入集群，并在重启后将宕机期间的数据自动同步到此节点上。 文件目录结构 运行与安装（单节点）一、准备工作(俩台机器同时进行)1.下载软件: http://sourceforge.net/projects/fastdfs/files/2安装gcc。命令:yum install make cmake gcc gcc-c++ 3 安装libfastcommon(俩台机器同时进行)&nbsp;&nbsp;3.1 上传libfastcommon-master.zip到/usr/local/software下&nbsp;&nbsp;3.2 进行解压libfastcommon-master.zip:命令:unzip libfastcommon-master.zip -d /usr/local/fast/&nbsp;&nbsp;3.3 进入目录:cd /usr/local/fast/libfastcommon-master/ 4 进行编译和安装:命令:&nbsp;&nbsp;./make.sh命令:&nbsp;&nbsp;./make.sh install注意安装的路径:也就是说,我们的libfastcommon默认安装到了/usr/lib64/这个位置。 5 进行软件创建。FastDFS主程序设置的目录为/usr/local/lib/,所以我们需要创建/usr/lib64/下的一些核心执行程序的软连接文件。命令:mk dir /usr/local/lib/命令:ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so命令:ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so命令:ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so命令:ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so6、安装FastDFS&nbsp;&nbsp;6.1 进入到cd /usr/local/software下,解压FastDFS_v5.05.tar.gz文件&nbsp;&nbsp;命令:cd /usr/local/software&nbsp;&nbsp;命令:tar -zxvf FastDFS_v5.05.tar.gz -C /usr/local/fast/&nbsp;&nbsp;6.2安装编译&nbsp;&nbsp;命令:cd /usr/local/fast/FastDFS/&nbsp;&nbsp;编译命令:./make.sh&nbsp;&nbsp;安装命令:./make.sh install7 采用默认安装方式脚本文件说明:1、服务脚本在:/etc/init.d/fdfs_storaged/etc/init.d/fdfs_trackerd2、配置文件在:/etc/fdfs/client.conf.sample/etc/fdfs/storage.conf.sample/etc/fdfs/tracker.conf.sample3、命令行工具在/usr/bin/目录下Fdfs_*的一些列执行脚本4 因为FastDFS服务脚本设置的bin目录为/usr/local/bin/下,但是实际我们安装在了/usr/bin/下面。所以我们需要修改FastDFS配置文件中的路径,也就是需要修改俩个配置文件:命令:vim /etc/init.d/fdfs_storaged进行全局替换命令:%s+/usr/local/bin+/usr/bin命令:vim /etc/init.d/fdfs_trackerd进行全局替换命令:%s+/usr/local/bin+/usr/bin4、配置跟踪器(192.168.1.172节点)1进入cd/etc/fdfs/目录配置跟踪器文件(注意是192.168.1.172节点),把tracker.conf.sample文件进行cope一份:去修改tracker.conf文件 2 修改tracker.conf文件命令:vim /etc/fdfs/tracker.conf如下图所示:我们暂时修改配置文件里的base_path即可。 修改为自己的路径地址:base_path=/fastdfs/tracker注意:对于tracker.conf配置文件参数解释可以找官方文档,地址为:http://bbs.chinaunix.net/thread-1941456-1-1.html3 最后我们一定要创建之前定义好的目录(也就是/fastdfs/tracker):命令:mkdir -p /fastdfs/tracker4 关闭防火墙:(我们在学习时可以不用考虑防火墙的问题)vim /etc/sysconfig/iptables添加:-A INPUT -m state –state NEW -m tcp -p tcp –dport 22122 -j ACCEPT重启:service iptables restart5 启动跟踪器如图所示: 目录命令:cd /fastdfs/tracker/ &amp;&amp; ll启动tracker命令:/etc/init.d/fdfs_trackerd start查看进程命令:ps -el | grep fdfs停止tracker命令:/etc/init.d/fdfs_trackerd stop 6可以设置开机启动跟踪器:(一般生产环境需要开机启动一些服务,如keepalived、linux、tomcat等等)命令:vim /etc/rc.d/rc.local加入配置:/etc/init.d/fdfs_trackerd start 5、配置FastDFS存储(192.168.1.173)1 进入文件目录:cd /etc/fdfs/,进行copy storage文件一份命令:cd /etc/fdfs/命令:cp storage.conf.sample storage.conf2 修改storage.conf文件命令:vim /etc/fdfs/storage.conf修改内容:base_path=/fastdfs/storagestore_path0=/fastdfs/storagetracker_server=192.168.1.172:22122http.server_port=88883 创建存储目录:mkdir -p /fastdfs/storage4 打开防火墙:命令:vim /etc/sysconfig/iptables添加:-A INPUT -m state –state NEW -m tcp -p tcp –dport 23000 -j ACCEPT重启:service iptables restart5 启动存储(storage)命令:/etc/init.d/fdfs_storaged start (关闭:/etc/init.d/fdfs_storaged stop)(初次启动成功后会在/fastdbf/storage/ 目录下创建 data、logs俩个目录)6 查看FastDFS storage 是否启动成功命令:ps -ef | grep fdfs并且我们进入到/fastdfs/storage/data/文件夹下会看到一些目录文件(256*256),如下:命令:cd /fastdfs/storage/data/ &amp;&amp; ls7 同理,也可以设置开机启动存储器:(一般生产环境需要开机启动一些服务,如keepalived、linux、tomcat等等)命令:vim /etc/rc.d/rc.local加入配置:/etc/init.d/fdfs_storaged start到此为止我们的FastDFS环境已经搭建完成。。。 验证环境1 我们先使用命令上传一个文件。注意:是在tracker(跟踪器)中上传。首先我们在跟踪器(192.168.1.172)里copy一份client.conf文件。命令:cd /etc/fdfs/命令:cp client.conf.sample client.conf 2 编辑client.conf文件命令:vim /etc/fdfs/client.conf修改内容:base_path=/fastdfs/trackertracker_server=192.168.1.172:221223 我们找到命令的脚本位置,并且使用命令,进行文件的上传:命令:cd /usr/bin/命令:ls | grep fdfs 4 使用命令fdfs_upload_file进行上传操作:首先,我们先看一下存储器(192.168.1.173),进入到data下,在进入00文件夹下,发现00文件夹下还有一堆文件夹,然后继续进入00文件夹下,最终我们所进入的文件夹为:/fastdfs/storage/data/00/00 里面什么文件都没有。 然后,我们进行上传操作,比如把之前的/usr/local/software/文件夹下的某一个文件上传到FastDFS系统中去,在跟踪器(192.168.1.172)中上传文件,命令如下:命令:/usr/bin/fdfs_upload_file /etc/fdfs/client.conf/usr/local/software/FastDFS_v5.05.tar.gz 最后我们发现,命令执行完毕后,返回一个group1/M00/00/00/…的ID,其实就是返回当前所上传的文件在存储器(192.168.1.173)中的哪一个组、哪一个目录位置,所以我们查看存储器中的/fastdfs/storage/data/00/00文件夹位置,发现已经存在了刚才上传的文件,到此为止,我们的测试上传文件已经OK了。如下 7、FastDFS与Nginx整合1 首先两台机器里必须先安装nginx2然后我们在存储节点上(192.168.1.173)安装fastdfs-nginx-module_v1.16.tar.gz包进行整合。 目录命令:cd /usr/local/software/解压命令:tar -zxvf /usr/local/software/fastdfs-nginx-module_v1.16.tar.gz -C /usr/local/fast/3 进入目录:cd fastdfs-nginx-module/src/ 4 编辑配置文件config命令: vim /usr/local/fast/fastdfs-nginx-module/src/config修改内容:去掉下图中的local文件层次 修改完毕为: 5 FastDFS与nginx进行集成首先把之前的nginx进行删除目录命令:cd /usr/local/删除命令:rm -rf nginx进入到nginx目录命令:cd nginx-1.6.2/加入模块命令:./configure –add-module=/usr/local/fast/fastdfs-nginx-module/src/重新编译命令:make &amp;&amp; make install6 复制fastdfs-ngin-module中的配置文件,到/etc/fdfs目录中,如图所示: copy命令:cp /usr/local/fast/fastdfs-nginx-module/src/mod_fastdfs.conf /etc/fdfs/7 进行修改 /etc/fdfs/ 目录下,我们刚刚copy过来的mod_fastdfs.conf 文件。 命令:vim /etc/fdfs/mod_fastdfs.conf修改内容:比如连接超时时间、跟踪器路径配置、url的group配置、connect_timeout=10tracker_server=192.168.1.172:22122url_have_group_name = truestore_path0=/fastdfs/storage8 复制FastDFS里的2个文件,到/etc/fdfs目录中,如图所示: 目录命令:cd /usr/local/fast/FastDFS/conf/Copy命令:cp http.conf mime.types /etc/fdfs/9创建一个软连接,在/fastdfs/storage文件存储目录下创建软连接,将其链接到实际存放数据的目录。命令:ln -s /fastdfs/storage/data/ /fastdfs/storage/data/M0010 修改Nginx配置文件,如图所示: 命令:vim nginx.conf修改配置内容如下图所示: 修改内容为:listen 8888;server_name localhost;location ~/group([0-9])/M00 { #alias /fastdfs/storage/data;ngx_fastdfs_module;}注意:nginx里的端口要和第五步配置FastDFS存储中的storage.conf文件配置一致,也就是(http.server_port=8888)11 最后检查防火墙,然后我们启动nginx服务 启动命令:/usr/local/nginx/sbin/nginx,我们刚才上传了一个文件,上传成功,如图: 现在我们使用这个ID用浏览器访问地址:http://192.168.1.173:8888/group1/M00/00/00/wKgBrVaSvM6AddWWAAVFOL7FJU4.tar.gz我们就可以下载这个文件啦!如下图所示: 运维注意:我们在使用FastDFS的时候,需要正常关机,不要使用kill -9强杀FastDFS进程,不然会在文件上传时出现丢数据的情况。到此,我们的FastDFS与Nginx整合完毕!!八:启动停止服务步骤如下:启动命令:启动tracker命令:/etc/init.d/fdfs_trackerd start查看进程命令:ps -el | grep fdfs启动storage命令:/etc/init.d/fdfs_storaged start查看进程命令:ps -el | grep fdfs启动nginx命令:/usr/local/nginx/sbin/nginx停止命令:停止tracker命令:/etc/init.d/fdfs_trackerd stop关闭storage命令:/etc/init.d/fdfs_storaged stop关闭nginx命令:/usr/local/nginx/sbin/nginx -s stop 集群环境安装集群环境安装我就稍微简略点了，99%是相同的，说下差异点，主要是一个group的区分，单节点tracker时没指定group，默认为group0首先准备几台机器192.168.1.113 track-group1192.168.1.114 track-group2192.168.1.115 storage-group1-1192.168.1.116 storage-group1-2192.168.1.117 storage-group2-1192.168.1.118 storage-group2-2 创建tracker节点无区别，依葫芦画瓢创建storage节点时需要指明并区分当前storage节点是挂载在哪个tracker下group的概念主要是为了区分不同的数据来源，可能来自不能的系统，不同的应用，当然在文件传输时不指明group会依照nginx的负载均衡算法(轮询，权重等)分配groupeg: 115 116为group1 117 118为group2vim storage.confgroup_name = group1(或group2)首先一定要启动tracker，之后启动storage，查看日志我们可以发现两个tracker是能互相知道对方的，更能知道当前tracker下挂载了多少个storage，此时storage集群中，拿115 116为例子，一个group中的数据永远是相同的，之间异步进行文件的备份，实现高可用，如果此时115宕机，115会被剔除出group1，恢复后从116进行文件的恢复，并再次加入集群ok,当我们系统中存在多个tracker集群时,此时tracker就不应该直接与客户端通信，在nginx网管层(多层nginx+keeplived虚拟出svip)进行负载均衡 java客户端操作此处结合spring＋mybatis＋springmvc来进行操作，ssm的基本配置不需多说 导入依赖,国产的，包里的代码都有详细的注释，一目了然 12345&lt;dependency&gt; &lt;groupId&gt;com.github.tobato&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client&lt;/artifactId&gt; &lt;version&gt;1.25.4-RELEASE&lt;/version&gt;&lt;/dependency&gt; 添加springmvc中multipartFile的bean配置，此处可以进行文件类型，文件大小，文件编码等设置，不细说，网上一大把 123&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt;&lt;/bean&gt; 添加fastdfs客户端连接配置，主要是一些连接器，连接池的配置，也可以进行超时时间，签名验签token校验等，这里给出最进本的配置 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--配置扫描包--&gt; &lt;context:component-scan base-package=&quot;com.github.tobato.fastdfs.service,com.github.tobato.fastdfs.domain&quot;/&gt; &lt;!--配置连接管理器--&gt; &lt;bean id=&quot;trackerConnectionManager&quot; class=&quot;com.github.tobato.fastdfs.conn.TrackerConnectionManager&quot;&gt; &lt;constructor-arg name=&quot;pool&quot; ref=&quot;fdfsConnectionPool&quot;&gt; &lt;/constructor-arg&gt; &lt;!--配置fastDFS tracker 服务器 ip:port 地址--&gt; &lt;property name=&quot;trackerList&quot;&gt; &lt;list&gt; &lt;value&gt;10.211.55.5:22122&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!--配置连接池--&gt; &lt;bean id=&quot;fdfsConnectionPool&quot; class=&quot;com.github.tobato.fastdfs.conn.FdfsConnectionPool&quot;&gt; &lt;!--注入连接池配置--&gt; &lt;constructor-arg name=&quot;config&quot; &gt; &lt;bean class=&quot;com.github.tobato.fastdfs.conn.ConnectionPoolConfig&quot;/&gt; &lt;/constructor-arg&gt; &lt;!--注入连接池工厂--&gt; &lt;constructor-arg name=&quot;factory&quot; &gt; &lt;bean class=&quot;com.github.tobato.fastdfs.conn.PooledConnectionFactory&quot;/&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; 4.编写test类demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package org.seckill;import com.github.tobato.fastdfs.domain.StorePath;import com.github.tobato.fastdfs.service.FastFileStorageClient;import org.junit.Test;import org.junit.runner.RunWith;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.AbstractJUnit4SpringContextTests;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import javax.annotation.Resource;import java.io.File;import java.io.FileInputStream;@ContextConfiguration(locations = &#123;&quot;classpath:spring/spring-fastdfs.xml&quot;&#125;)@RunWith(SpringJUnit4ClassRunner.class)public class FastDFSDemo extends AbstractJUnit4SpringContextTests &#123; private static final Logger logger = LoggerFactory.getLogger(FastDFSDemo.class); @Resource private FastFileStorageClient fastFileStorageClient; /** *上传 * * @author ❤ xiemao * @date : 18/11/01 下午8:14 */ @Test public void uploadFile() throws Exception &#123; File file = new File(&quot;/Users/xie199475/备份/provider/src/main/resources/file_source/001.jpg&quot;); StorePath storePath = fastFileStorageClient. uploadFile(null, new FileInputStream(file), file.length(), &quot;jpg&quot;); logger.info(&quot;------:&#123;&#125;&quot;,storePath.getFullPath()); &#125; /** *删除 * * @author ❤ xiemao * @date : 18/11/01 下午8:15 */ @Test public void delete()&#123; String path = &quot;group1/M00/00/00/CtM3BlvUxfGAaC-fAAVFOL7FJU4.tar.gz&quot;; fastFileStorageClient.deleteFile(path); logger.info(&quot;----ok&quot;); &#125; &#125; 12345678910111213141516171819@RequestMapping(value = &quot;/upload&quot;, method = RequestMethod.POST) public void upload(MultipartFile file, FileUpload fileUpload) throws IOException &#123; StorePath storePath = fastFileStorageClient. uploadFile(null, new ByteArrayInputStream(file.getBytes()), Long.valueOf(fileUpload.getSize()), &quot;jpg&quot;); logger.info(&quot;------:&#123;&#125;&quot;, storePath.getFullPath()); &#125; @RequestMapping(value = &quot;/download&quot;, method = RequestMethod.POST) public void download(HttpServletResponse response) throws Exception &#123; try (OutputStream os = response.getOutputStream(); BufferedOutputStream bf = new BufferedOutputStream(os)) &#123; String groupName = &quot;group1&quot;; String path = &quot;M00/00/00/CtM3Blvj9PKAYquVAAD9K7ssbVE777.jpg&quot;; byte[] data = fastFileStorageClient.downloadFile(groupName, path, new DownloadByteArray()); IOUtils.write(data, bf); &#125; &#125; 配置文件参数说明storage.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114storage.conf配置文件分析：#同tracker.confdisabled=false #这个storage服务器属于那个groupgroup_name=group1 #同tracker.confbind_addr= #连接其他服务器时是否绑定地址，bind_addr配置时本参数才有效client_bind=true #同tracker.confport=23000connect_timeout=30network_timeout=60 #主动向tracker发送心跳检测的时间间隔heart_beat_interval=30 #主动向tracker发送磁盘使用率的时间间隔stat_report_interval=60 #同tracker.confbase_path=/opt/fdfsmax_connections=256 #接收/发送数据的buff大小，必须大于8KBbuff_size = 256KB #同tracker.confwork_threads=4 #磁盘IO是否读写分离disk_rw_separated = true #是否直接读写文件，默认关闭disk_rw_direct = false #混合读写时的读写线程数disk_reader_threads = 1disk_writer_threads = 1 #同步文件时如果binlog没有要同步的文件，则延迟多少毫秒后重新读取，0表示不延迟sync_wait_msec=50 #同步完一个文件后间隔多少毫秒同步下一个文件，0表示不休息直接同步sync_interval=0 #表示这段时间内同步文件sync_start_time=00:00sync_end_time=23:59 #同步完多少文件后写mark标记write_mark_file_freq=500 #storage在存储文件时支持多路径，默认只设置一个store_path_count=1 #配置多个store_path路径，从0开始，如果store_path0不存在，则base_path必须存在store_path0=/opt/fdfs#store_path1=/opt/fastdfs2 #subdir_count * subdir_count个目录会在store_path下创建，采用两级存储subdir_count_per_path=256 #设置tracker_servertracker_server=x.x.x.x:22122 #同tracker.conflog_level=inforun_by_group=run_by_user=allow_hosts=* #文件在数据目录下的存放策略，0:轮训 1:随机file_distribute_path_mode=0 #当问及是轮训存放时，一个目录下可存放的文件数目file_distribute_rotate_count=100 #写入多少字节后就开始同步，0表示不同步fsync_after_written_bytes=0 #刷新日志信息到disk的间隔sync_log_buff_interval=10 #同步storage的状态信息到disk的间隔sync_stat_file_interval=300 #线程栈大小thread_stack_size=512KB #设置文件上传服务器的优先级，值越小越高upload_priority=10 #是否检测文件重复存在，1:检测 0:不检测check_file_duplicate=0 #当check_file_duplicate设置为1时，次值必须设置key_namespace=FastDFS #与FastDHT建立连接的方式 0:短连接 1:长连接keep_alive=0 #同tracker.confhttp.disabled=falsehttp.domain_name=http.server_port=8888http.trunk_size=256KBhttp.need_find_content_type=true##include http.conf tracker.conf123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104tracker.conf 配置文件分析：#配置tracker.conf这个配置文件是否生效，因为在启动fastdfs服务端进程时需要指定配置文件，所以需要使次配置文件生效。false是生效，true是屏蔽。disabled=false #程序的监听地址，如果不设定则监听所有地址bind_addr= #tracker监听的端口port=22122 #链接超时设定connect_timeout=30 #tracker在通过网络发送接收数据的超时时间network_timeout=60 #数据和日志的存放地点base_path=/opt/fdfs #服务所支持的最大链接数max_connections=256 #工作线程数一般为cpu个数work_threads=4 #在存储文件时选择group的策略，0:轮训策略 1:指定某一个组 2:负载均衡，选择空闲空间最大的groupstore_lookup=2 #如果上面的store_lookup选择了1，则这里需要指定一个group#store_group=group2 #在group中的哪台storage做主storage，当一个文件上传到主storage后，就由这台机器同步文件到group内的其他storage上，0：轮训策略 1：根据ip地址排序，第一个 2:根据优先级排序，第一个store_server=0 #选择那个storage作为主下载服务器，0:轮训策略 1:主上传storage作为主下载服务器download_server=0 #选择文件上传到storage中的哪个(目录/挂载点),storage可以有多个存放文件的base path 0:轮训策略 2:负载均衡，选择空闲空间最大的store_path=0 #系统预留空间，当一个group中的任何storage的剩余空间小于定义的值，整个group就不能上传文件了reserved_storage_space = 4GB #日志信息级别log_level=info #进程以那个用户/用户组运行，不指定默认是当前用户run_by_group=run_by_user= #允许那些机器连接tracker默认是所有机器allow_hosts=* #设置日志信息刷新到disk的频率，默认10ssync_log_buff_interval = 10 #检测storage服务器的间隔时间，storage定期主动向tracker发送心跳，如果在指定的时间没收到信号，tracker人为storage故障，默认120scheck_active_interval = 120 #线程栈的大小，最小64Kthread_stack_size = 64KB #storage的ip改变后服务端是否自动调整，storage进程重启时才自动调整storage_ip_changed_auto_adjust = true #storage之间同步文件的最大延迟，默认1天storage_sync_file_max_delay = 86400 #同步一个文件所花费的最大时间storage_sync_file_max_time = 300 #是否用一个trunk文件存储多个小文件use_trunk_file = false #最小的solt大小，应该小于4KB，默认256bytesslot_min_size = 256 #最大的solt大小，如果上传的文件小于默认值，则上传文件被放入trunk文件中slot_max_size = 16MB #trunk文件的默认大小，应该大于4Mtrunk_file_size = 64MB #http服务是否生效，默认不生效http.disabled=false #http服务端口http.server_port=8080 #检测storage上http服务的时间间隔，&lt;=0表示不检测http.check_alive_interval=30 #检测storage上http服务时所用请求的类型，tcp只检测是否可以连接，http必须返回200http.check_alive_type=tcp #通过url检测storage http服务状态http.check_alive_uri=/status.html #if need find content type from file extension namehttp.need_find_content_type=true #用include包含进http的其他设置##include http.conf over :)]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>fastdfs</tag>
        <tag>文件存储</tag>
      </tags>
  </entry>
</search>
